{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "codeTrans_function_documentation_generation_ruby_code_base",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNC6xHIdirrWuXnzGBvwVCn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/agemagician/CodeTrans/blob/main/prediction/single%20task/function%20documentation%20generation/ruby/base_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YPrvwDIHdBe"
      },
      "source": [
        "## Install the library and download the pretrained models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WI23u_mBGZ7",
        "outputId": "e8601bd7-61cc-4808-956d-69078f5f50f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"Installing dependencies...\")\n",
        "%tensorflow_version 2.x\n",
        "!pip install -q t5==0.6.4\n",
        "\n",
        "import functools\n",
        "import os\n",
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "import tensorflow.compat.v1 as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "import t5\n",
        "\n",
        "!wget \"https://www.dropbox.com/sh/kjoqdpj7e16dny9/AADdvjWVFckCgNQN-AqMKhiDa?dl=1\" -O vocabulary.zip\n",
        "!unzip vocabulary.zip\n",
        "!rm vocabulary.zip\n",
        "!wget \"https://www.dropbox.com/sh/012r5jxhm5eiprt/AACxnFoc6egkqn8IJZvnoQsza?dl=1\" -O ruby.zip\n",
        "!unzip ruby.zip\n",
        "!rm ruby.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Installing dependencies...\n",
            "\u001b[K     |████████████████████████████████| 163kB 4.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.6MB 8.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.3MB 36.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.6MB 49.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1MB 49.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 8.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 348kB 40.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 890kB 45.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.9MB 48.7MB/s \n",
            "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: transformers 3.5.0 has requirement sentencepiece==0.1.91, but you'll have sentencepiece 0.1.94 which is incompatible.\u001b[0m\n",
            "INFO:tensorflow:tokens_length=568 inputs_length=512 targets_length=114 noise_density=0.15 mean_noise_span_length=3.0 \n",
            "--2020-11-10 13:56:44--  https://www.dropbox.com/sh/kjoqdpj7e16dny9/AADdvjWVFckCgNQN-AqMKhiDa?dl=1\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.1.1, 2620:100:6016:1::a27d:101\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.1.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /sh/dl/kjoqdpj7e16dny9/AADdvjWVFckCgNQN-AqMKhiDa [following]\n",
            "--2020-11-10 13:56:44--  https://www.dropbox.com/sh/dl/kjoqdpj7e16dny9/AADdvjWVFckCgNQN-AqMKhiDa\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucc660c8dc1c952443677d3866cb.dl.dropboxusercontent.com/zip_download_get/AmXAda3vKjuJeTf6TrpFCti-PmvmJFOkj7FXvtGRB6HKSlCKoGAcPeizlPHSfKp8z7L86TeT2fIqNhQE2YdhpRlIXEM4gNXiAm2Ka9Ujl0MqXA?dl=1 [following]\n",
            "--2020-11-10 13:56:44--  https://ucc660c8dc1c952443677d3866cb.dl.dropboxusercontent.com/zip_download_get/AmXAda3vKjuJeTf6TrpFCti-PmvmJFOkj7FXvtGRB6HKSlCKoGAcPeizlPHSfKp8z7L86TeT2fIqNhQE2YdhpRlIXEM4gNXiAm2Ka9Ujl0MqXA?dl=1\n",
            "Resolving ucc660c8dc1c952443677d3866cb.dl.dropboxusercontent.com (ucc660c8dc1c952443677d3866cb.dl.dropboxusercontent.com)... 162.125.1.15, 2620:100:6016:15::a27d:10f\n",
            "Connecting to ucc660c8dc1c952443677d3866cb.dl.dropboxusercontent.com (ucc660c8dc1c952443677d3866cb.dl.dropboxusercontent.com)|162.125.1.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1381528 (1.3M) [application/zip]\n",
            "Saving to: ‘vocabulary.zip’\n",
            "\n",
            "vocabulary.zip      100%[===================>]   1.32M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2020-11-10 13:56:45 (9.18 MB/s) - ‘vocabulary.zip’ saved [1381528/1381528]\n",
            "\n",
            "Archive:  vocabulary.zip\n",
            "warning:  stripped absolute path spec from /\n",
            "mapname:  conversion of  failed\n",
            " extracting: code_spm_unigram_40M.model  \n",
            " extracting: code_spm_unigram_40M.vocab  \n",
            "--2020-11-10 13:56:45--  https://www.dropbox.com/sh/012r5jxhm5eiprt/AACxnFoc6egkqn8IJZvnoQsza?dl=1\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.1.1, 2620:100:6016:1::a27d:101\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.1.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /sh/dl/012r5jxhm5eiprt/AACxnFoc6egkqn8IJZvnoQsza [following]\n",
            "--2020-11-10 13:56:45--  https://www.dropbox.com/sh/dl/012r5jxhm5eiprt/AACxnFoc6egkqn8IJZvnoQsza\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucaf244d38162244278d91e0e04f.dl.dropboxusercontent.com/zip_download_get/AmX3dlsZTezy2N-iw9_-Ooi4yA3Mc_GB8eNj4iThPzZGkFJviH4kCySKrYO9dFY8S7gOlicuzGXiOdJ8IhTSXYKVsGRR09wHCJTxkrR67tn9Iw?dl=1 [following]\n",
            "--2020-11-10 13:56:46--  https://ucaf244d38162244278d91e0e04f.dl.dropboxusercontent.com/zip_download_get/AmX3dlsZTezy2N-iw9_-Ooi4yA3Mc_GB8eNj4iThPzZGkFJviH4kCySKrYO9dFY8S7gOlicuzGXiOdJ8IhTSXYKVsGRR09wHCJTxkrR67tn9Iw?dl=1\n",
            "Resolving ucaf244d38162244278d91e0e04f.dl.dropboxusercontent.com (ucaf244d38162244278d91e0e04f.dl.dropboxusercontent.com)... 162.125.1.15, 2620:100:6016:15::a27d:10f\n",
            "Connecting to ucaf244d38162244278d91e0e04f.dl.dropboxusercontent.com (ucaf244d38162244278d91e0e04f.dl.dropboxusercontent.com)|162.125.1.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 658504252 (628M) [application/zip]\n",
            "Saving to: ‘ruby.zip’\n",
            "\n",
            "ruby.zip            100%[===================>] 628.00M  41.7MB/s    in 17s     \n",
            "\n",
            "2020-11-10 13:57:04 (36.5 MB/s) - ‘ruby.zip’ saved [658504252/658504252]\n",
            "\n",
            "Archive:  ruby.zip\n",
            "warning:  stripped absolute path spec from /\n",
            "mapname:  conversion of  failed\n",
            "   creating: base/\n",
            "   creating: small/\n",
            " extracting: base/command            \n",
            " extracting: small/command           \n",
            " extracting: base/command.1          \n",
            " extracting: small/command.1         \n",
            " extracting: base/checkpoint         \n",
            " extracting: small/checkpoint        \n",
            " extracting: base/graph.pbtxt        \n",
            " extracting: small/graph.pbtxt       \n",
            " extracting: small/t5_code_tasks.py  \n",
            " extracting: base/model.ckpt-8000.meta  \n",
            " extracting: base/operative_config.gin  \n",
            " extracting: base/model.ckpt-8000.index  \n",
            " extracting: small/operative_config.gin  \n",
            " extracting: small/model.ckpt-10000.meta  \n",
            " extracting: base/t5_code_tasks_colab.py  \n",
            " extracting: small/model.ckpt-10000.index  \n",
            " extracting: base/model.ckpt-8000.data-00000-of-00002  \n",
            " extracting: base/model.ckpt-8000.data-00001-of-00002  \n",
            " extracting: small/model.ckpt-10000.data-00001-of-00002  \n",
            " extracting: small/model.ckpt-10000.data-00000-of-00002  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbW4aF7hHosN"
      },
      "source": [
        "## Set sentencepiece model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0SXWeKu9B5U",
        "outputId": "7455fee4-c0a0-4ef0-967f-16a3c16d0dc5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from t5.data.sentencepiece_vocabulary import SentencePieceVocabulary\n",
        "\n",
        "vocab_model_path = 'code_spm_unigram_40M.model'\n",
        "vocab = SentencePieceVocabulary(vocab_model_path, extra_ids=100)\n",
        "\n",
        "print(\"Vocab has a size of %d\\n\" % vocab.vocab_size)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocab has a size of 32100\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VpxgigMIGbv"
      },
      "source": [
        "## Set the preprocessors and the task registry for the t5 model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "meFeWitk-TE3"
      },
      "source": [
        "def ruby_codeSearchNet_dataset_fn(split, shuffle_files=False):\n",
        "    tf.random.shuffle(ruby_path[split])\n",
        "\n",
        "    ds = tf.data.TextLineDataset(ruby_path[split])\n",
        "    ds = ds.map(\n",
        "        functools.partial(tf.io.decode_csv, record_defaults=[\"\", \"\"], field_delim=\"\\t\", use_quote_delim=False),\n",
        "        num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
        "    )\n",
        "    ds = ds.map(lambda *ex: dict(zip([\"code\", \"docstring\"], ex)))\n",
        "    return ds\n",
        "\n",
        "\n",
        "def ruby_preprocessor(ds):\n",
        "    def normalize_text(text):\n",
        "        return text\n",
        "\n",
        "    def to_inputs_and_targets(ex):\n",
        "        return {\n",
        "            \"inputs\": tf.strings.join([\"function documentation generation ruby: \", normalize_text(ex[\"code\"])]),\n",
        "            \"targets\": normalize_text(ex[\"docstring\"])\n",
        "        }\n",
        "\n",
        "    return ds.map(to_inputs_and_targets, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "\n",
        "t5.data.TaskRegistry.remove('function_documentation_generation_ruby_code')\n",
        "t5.data.TaskRegistry.add(\n",
        "    \"function_documentation_generation_ruby_code\",\n",
        "    dataset_fn=ruby_codeSearchNet_dataset_fn,\n",
        "    output_features={\n",
        "        \"inputs\": t5.data.utils.Feature(vocabulary=vocab),\n",
        "        \"targets\": t5.data.utils.Feature(vocabulary=vocab),\n",
        "    },\n",
        "    splits=[\"train\", \"validation\"],\n",
        "    text_preprocessor=[ruby_preprocessor],\n",
        "    postprocess_fn=t5.data.postprocessors.lower_text,\n",
        "    metric_fns=[t5.evaluation.metrics.bleu, t5.evaluation.metrics.accuracy, t5.evaluation.metrics.rouge],\n",
        ")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjZN7C7wISzq"
      },
      "source": [
        "## Set t5 base model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWBKPR24BweX"
      },
      "source": [
        "MODEL_DIR = \"base\"\n",
        "model_parallelism = 1\n",
        "train_batch_size = 256\n",
        "\n",
        "tf.io.gfile.makedirs(MODEL_DIR)\n",
        "model = t5.models.MtfModel(\n",
        "    model_dir=MODEL_DIR,\n",
        "    tpu=None,\n",
        "    tpu_topology=None,\n",
        "    model_parallelism=model_parallelism,\n",
        "    batch_size=train_batch_size,\n",
        "    sequence_length={\"inputs\": 512, \"targets\": 512},\n",
        "    mesh_shape=\"model:1,batch:1\",\n",
        "    mesh_devices=[\"GPU:0\"],\n",
        "    learning_rate_schedule=0.003,\n",
        "    save_checkpoints_steps=5000,\n",
        "    keep_checkpoint_max=None,\n",
        "    iterations_per_loop=100,\n",
        ")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yEE3ZQt5I3Jt"
      },
      "source": [
        "## Code Documentation Summarization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkynwKIcEvHh"
      },
      "source": [
        "### Give the code for summarization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nld-UUmII-2e"
      },
      "source": [
        "code = \"def add(severity, progname, &block)\\n      return true if io.nil? || severity < level\\n      message = format_message(severity, progname, yield)\\n      MUTEX.synchronize { io.write(message) }\\n      true\\n    end\" #@param {type:\"raw\"}\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfuU0WNfcDTe"
      },
      "source": [
        "### Parsing and Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90Y2MqKzcCsw",
        "outputId": "4f60828f-0347-4c30-9735-7a18c2f3890a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install tree_sitter\n",
        "!git clone https://github.com/tree-sitter/tree-sitter-ruby"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tree_sitter\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/52/26d11536a8fafaadabe9deeb0611abdd71e11602904f60a6debdde053e6f/tree_sitter-0.2.0.tar.gz (110kB)\n",
            "\r\u001b[K     |███                             | 10kB 17.0MB/s eta 0:00:01\r\u001b[K     |██████                          | 20kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████                       | 30kB 4.1MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 40kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 51kB 3.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 61kB 4.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 71kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 81kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 92kB 5.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 102kB 5.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 112kB 5.5MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: tree-sitter\n",
            "  Building wheel for tree-sitter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tree-sitter: filename=tree_sitter-0.2.0-cp36-cp36m-linux_x86_64.whl size=297407 sha256=ef192afa2e0c71f29444bc185273489489f08e5c8d9d3e4046c2c6b134001853\n",
            "  Stored in directory: /root/.cache/pip/wheels/3b/a6/01/2290cc8441301a07e7717e9e03c6bbc0388f71c6bf1f7f37c1\n",
            "Successfully built tree-sitter\n",
            "Installing collected packages: tree-sitter\n",
            "Successfully installed tree-sitter-0.2.0\n",
            "Cloning into 'tree-sitter-ruby'...\n",
            "remote: Enumerating objects: 34, done.\u001b[K\n",
            "remote: Counting objects: 100% (34/34), done.\u001b[K\n",
            "remote: Compressing objects: 100% (27/27), done.\u001b[K\n",
            "remote: Total 9306 (delta 12), reused 17 (delta 7), pack-reused 9272\u001b[K\n",
            "Receiving objects: 100% (9306/9306), 286.99 MiB | 27.24 MiB/s, done.\n",
            "Resolving deltas: 100% (4054/4054), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0PcDEX5cMGs"
      },
      "source": [
        "from tree_sitter import Language, Parser\n",
        "\n",
        "Language.build_library(\n",
        "  'build/my-languages.so',\n",
        "  ['tree-sitter-ruby']\n",
        ")\n",
        "\n",
        "RUBY_LANGUAGE = Language('build/my-languages.so', 'ruby')\n",
        "parser = Parser()\n",
        "parser.set_language(RUBY_LANGUAGE)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAVo9E0McOsc"
      },
      "source": [
        "def get_string_from_code(node, lines):\n",
        "  line_start = node.start_point[0]\n",
        "  line_end = node.end_point[0]\n",
        "  char_start = node.start_point[1]\n",
        "  char_end = node.end_point[1]\n",
        "  if line_start != line_end:\n",
        "    code_list.append(' '.join([lines[line_start][char_start:]] + lines[line_start+1:line_end] + [lines[line_end][:char_end]]))\n",
        "  else:\n",
        "    code_list.append(lines[line_start][char_start:char_end])\n",
        "\n",
        "def my_traverse(node, code_list):\n",
        "  lines = code.split('\\n')\n",
        "  if node.child_count == 0:\n",
        "    get_string_from_code(node, lines)\n",
        "  elif node.type == 'string':\n",
        "    get_string_from_code(node, lines)\n",
        "  else:\n",
        "    for n in node.children:\n",
        "      my_traverse(n, code_list)\n",
        " \n",
        "  return ' '.join(code_list)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKWVI-ZQcRrt",
        "outputId": "423a5959-fd79-4180-fccb-12315ab9fcea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tree = parser.parse(bytes(code, \"utf8\"))\n",
        "code_list=[]\n",
        "tokenized_code = my_traverse(tree.root_node, code_list)\n",
        "print(\"Output after tokenization: \" + tokenized_code)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Output after tokenization: def add ( severity , progname , & block ) return true if io . nil? || severity < level message = format_message ( severity , progname , yield ) MUTEX . synchronize { io . write ( message ) } true end\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUGjYiWzJSu0"
      },
      "source": [
        "### Record the code for summarization with the prefix to a txt file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCGjrieBJck1"
      },
      "source": [
        "codes = [tokenized_code]\n",
        "\n",
        "inputs_path = 'input.txt'\n",
        "with tf.io.gfile.GFile(inputs_path, \"w\") as f:\n",
        "  for c in codes:\n",
        "    f.write(\"function documentation generation ruby: %s\\n\" % c)\n",
        "\n",
        "predict_outputs_path = 'MtfModel-output.txt'\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PK_kyR4VJlha"
      },
      "source": [
        "### Running the model with the best checkpoint to summarize the given code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdThL03VDNX3",
        "outputId": "8bdb25c9-f42b-4595-ca10-02bc001af311",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.batch_size = 8 \n",
        "model.predict(\n",
        "    input_file=\"input.txt\",\n",
        "    output_file=predict_outputs_path,\n",
        "    checkpoint_steps=8000,\n",
        "    beam_size=4,\n",
        "    vocabulary=vocab, \n",
        "    # Select the most probable output token at each step.\n",
        "    temperature=0,\n",
        ")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': 'base', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=100, num_shards=None, num_cores_per_replica=1, per_host_input_for_training=4, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1), '_cluster': None}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
            "WARNING:tensorflow:eval_on_tpu ignored because use_tpu is False.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Running infer on CPU/GPU\n",
            "INFO:tensorflow:feature inputs : Tensor(\"Reshape:0\", shape=(8, 512), dtype=int32)\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/k                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/o                  size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/q                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias size 384          slice_size 384          Shape[heads=12, buckets=32]                                 \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/v                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/rms_norm/scale                   size 768          slice_size 768          Shape[d_model=768]                                          \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/k                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/o                size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/q                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/v                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/rms_norm/scale                   size 768          slice_size 768          Shape[d_model=768]                                          \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wi/kernel         size 2359296      slice_size 2359296      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wo/kernel         size 2359296      slice_size 2359296      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/rms_norm/scale                   size 768          slice_size 768          Shape[d_model=768]                                          \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/k                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/o                  size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/q                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/v                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/rms_norm/scale                   size 768          slice_size 768          Shape[d_model=768]                                          \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/k                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/o                size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/q                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/v                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/rms_norm/scale                   size 768          slice_size 768          Shape[d_model=768]                                          \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wi/kernel         size 2359296      slice_size 2359296      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wo/kernel         size 2359296      slice_size 2359296      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/rms_norm/scale                   size 768          slice_size 768          Shape[d_model=768]                                          \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/k                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/o                  size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/q                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/v                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/rms_norm/scale                   size 768          slice_size 768          Shape[d_model=768]                                          \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/k                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/o                size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/q                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/v                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/rms_norm/scale                   size 768          slice_size 768          Shape[d_model=768]                                          \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wi/kernel         size 2359296      slice_size 2359296      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wo/kernel         size 2359296      slice_size 2359296      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/rms_norm/scale                   size 768          slice_size 768          Shape[d_model=768]                                          \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/k                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/o                  size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/q                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/v                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/rms_norm/scale                   size 768          slice_size 768          Shape[d_model=768]                                          \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/k                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/o                size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/q                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/v                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/rms_norm/scale                   size 768          slice_size 768          Shape[d_model=768]                                          \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wi/kernel         size 2359296      slice_size 2359296      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wo/kernel         size 2359296      slice_size 2359296      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/rms_norm/scale                   size 768          slice_size 768          Shape[d_model=768]                                          \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/k                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/o                  size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/q                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/v                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/rms_norm/scale                   size 768          slice_size 768          Shape[d_model=768]                                          \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/k                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/o                size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/q                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/v                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/rms_norm/scale                   size 768          slice_size 768          Shape[d_model=768]                                          \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wi/kernel         size 2359296      slice_size 2359296      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wo/kernel         size 2359296      slice_size 2359296      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/rms_norm/scale                   size 768          slice_size 768          Shape[d_model=768]                                          \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/k                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/o                  size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/q                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/v                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/rms_norm/scale                   size 768          slice_size 768          Shape[d_model=768]                                          \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/k                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/o                size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/q                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/v                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/rms_norm/scale                   size 768          slice_size 768          Shape[d_model=768]                                          \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wi/kernel         size 2359296      slice_size 2359296      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wo/kernel         size 2359296      slice_size 2359296      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/rms_norm/scale                   size 768          slice_size 768          Shape[d_model=768]                                          \n",
            "INFO:tensorflow:Variable decoder/block_006/layer_000/SelfAttention/k                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_006/layer_000/SelfAttention/o                  size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_006/layer_000/SelfAttention/q                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_006/layer_000/SelfAttention/v                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_006/layer_000/rms_norm/scale                   size 768          slice_size 768          Shape[d_model=768]                                          \n",
            "INFO:tensorflow:Variable decoder/block_006/layer_001/EncDecAttention/k                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_006/layer_001/EncDecAttention/o                size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_006/layer_001/EncDecAttention/q                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_006/layer_001/EncDecAttention/v                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_006/layer_001/rms_norm/scale                   size 768          slice_size 768          Shape[d_model=768]                                          \n",
            "INFO:tensorflow:Variable decoder/block_006/layer_002/DenseReluDense/wi/kernel         size 2359296      slice_size 2359296      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable decoder/block_006/layer_002/DenseReluDense/wo/kernel         size 2359296      slice_size 2359296      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_006/layer_002/rms_norm/scale                   size 768          slice_size 768          Shape[d_model=768]                                          \n",
            "INFO:tensorflow:Variable decoder/block_007/layer_000/SelfAttention/k                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_007/layer_000/SelfAttention/o                  size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_007/layer_000/SelfAttention/q                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_007/layer_000/SelfAttention/v                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_007/layer_000/rms_norm/scale                   size 768          slice_size 768          Shape[d_model=768]                                          \n",
            "INFO:tensorflow:Variable decoder/block_007/layer_001/EncDecAttention/k                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_007/layer_001/EncDecAttention/o                size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_007/layer_001/EncDecAttention/q                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_007/layer_001/EncDecAttention/v                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_007/layer_001/rms_norm/scale                   size 768          slice_size 768          Shape[d_model=768]                                          \n",
            "INFO:tensorflow:Variable decoder/block_007/layer_002/DenseReluDense/wi/kernel         size 2359296      slice_size 2359296      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable decoder/block_007/layer_002/DenseReluDense/wo/kernel         size 2359296      slice_size 2359296      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_007/layer_002/rms_norm/scale                   size 768          slice_size 768          Shape[d_model=768]                                          \n",
            "INFO:tensorflow:Variable decoder/block_008/layer_000/SelfAttention/k                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_008/layer_000/SelfAttention/o                  size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_008/layer_000/SelfAttention/q                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_008/layer_000/SelfAttention/v                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_008/layer_000/rms_norm/scale                   size 768          slice_size 768          Shape[d_model=768]                                          \n",
            "INFO:tensorflow:Variable decoder/block_008/layer_001/EncDecAttention/k                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_008/layer_001/EncDecAttention/o                size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_008/layer_001/EncDecAttention/q                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_008/layer_001/EncDecAttention/v                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_008/layer_001/rms_norm/scale                   size 768          slice_size 768          Shape[d_model=768]                                          \n",
            "INFO:tensorflow:Variable decoder/block_008/layer_002/DenseReluDense/wi/kernel         size 2359296      slice_size 2359296      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable decoder/block_008/layer_002/DenseReluDense/wo/kernel         size 2359296      slice_size 2359296      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_008/layer_002/rms_norm/scale                   size 768          slice_size 768          Shape[d_model=768]                                          \n",
            "INFO:tensorflow:Variable decoder/block_009/layer_000/SelfAttention/k                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_009/layer_000/SelfAttention/o                  size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_009/layer_000/SelfAttention/q                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_009/layer_000/SelfAttention/v                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_009/layer_000/rms_norm/scale                   size 768          slice_size 768          Shape[d_model=768]                                          \n",
            "INFO:tensorflow:Variable decoder/block_009/layer_001/EncDecAttention/k                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_009/layer_001/EncDecAttention/o                size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_009/layer_001/EncDecAttention/q                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_009/layer_001/EncDecAttention/v                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_009/layer_001/rms_norm/scale                   size 768          slice_size 768          Shape[d_model=768]                                          \n",
            "INFO:tensorflow:Variable decoder/block_009/layer_002/DenseReluDense/wi/kernel         size 2359296      slice_size 2359296      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable decoder/block_009/layer_002/DenseReluDense/wo/kernel         size 2359296      slice_size 2359296      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_009/layer_002/rms_norm/scale                   size 768          slice_size 768          Shape[d_model=768]                                          \n",
            "INFO:tensorflow:Variable decoder/block_010/layer_000/SelfAttention/k                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_010/layer_000/SelfAttention/o                  size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_010/layer_000/SelfAttention/q                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_010/layer_000/SelfAttention/v                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_010/layer_000/rms_norm/scale                   size 768          slice_size 768          Shape[d_model=768]                                          \n",
            "INFO:tensorflow:Variable decoder/block_010/layer_001/EncDecAttention/k                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_010/layer_001/EncDecAttention/o                size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_010/layer_001/EncDecAttention/q                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_010/layer_001/EncDecAttention/v                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_010/layer_001/rms_norm/scale                   size 768          slice_size 768          Shape[d_model=768]                                          \n",
            "INFO:tensorflow:Variable decoder/block_010/layer_002/DenseReluDense/wi/kernel         size 2359296      slice_size 2359296      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable decoder/block_010/layer_002/DenseReluDense/wo/kernel         size 2359296      slice_size 2359296      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_010/layer_002/rms_norm/scale                   size 768          slice_size 768          Shape[d_model=768]                                          \n",
            "INFO:tensorflow:Variable decoder/block_011/layer_000/SelfAttention/k                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_011/layer_000/SelfAttention/o                  size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_011/layer_000/SelfAttention/q                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_011/layer_000/SelfAttention/v                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_011/layer_000/rms_norm/scale                   size 768          slice_size 768          Shape[d_model=768]                                          \n",
            "INFO:tensorflow:Variable decoder/block_011/layer_001/EncDecAttention/k                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_011/layer_001/EncDecAttention/o                size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_011/layer_001/EncDecAttention/q                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_011/layer_001/EncDecAttention/v                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_011/layer_001/rms_norm/scale                   size 768          slice_size 768          Shape[d_model=768]                                          \n",
            "INFO:tensorflow:Variable decoder/block_011/layer_002/DenseReluDense/wi/kernel         size 2359296      slice_size 2359296      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable decoder/block_011/layer_002/DenseReluDense/wo/kernel         size 2359296      slice_size 2359296      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_011/layer_002/rms_norm/scale                   size 768          slice_size 768          Shape[d_model=768]                                          \n",
            "INFO:tensorflow:Variable decoder/rms_norm/scale                                       size 768          slice_size 768          Shape[d_model=768]                                          \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/k                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/o                  size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/q                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias size 384          slice_size 384          Shape[heads=12, buckets=32]                                 \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/v                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/rms_norm/scale                   size 768          slice_size 768          Shape[d_model=768]                                          \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wi/kernel         size 2359296      slice_size 2359296      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wo/kernel         size 2359296      slice_size 2359296      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/rms_norm/scale                   size 768          slice_size 768          Shape[d_model=768]                                          \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/k                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/o                  size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/q                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/v                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/rms_norm/scale                   size 768          slice_size 768          Shape[d_model=768]                                          \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wi/kernel         size 2359296      slice_size 2359296      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wo/kernel         size 2359296      slice_size 2359296      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/rms_norm/scale                   size 768          slice_size 768          Shape[d_model=768]                                          \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/k                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/o                  size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/q                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/v                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/rms_norm/scale                   size 768          slice_size 768          Shape[d_model=768]                                          \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wi/kernel         size 2359296      slice_size 2359296      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wo/kernel         size 2359296      slice_size 2359296      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/rms_norm/scale                   size 768          slice_size 768          Shape[d_model=768]                                          \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/k                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/o                  size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/q                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/v                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/rms_norm/scale                   size 768          slice_size 768          Shape[d_model=768]                                          \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wi/kernel         size 2359296      slice_size 2359296      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wo/kernel         size 2359296      slice_size 2359296      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/rms_norm/scale                   size 768          slice_size 768          Shape[d_model=768]                                          \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/k                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/o                  size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/q                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/v                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/rms_norm/scale                   size 768          slice_size 768          Shape[d_model=768]                                          \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wi/kernel         size 2359296      slice_size 2359296      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wo/kernel         size 2359296      slice_size 2359296      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/rms_norm/scale                   size 768          slice_size 768          Shape[d_model=768]                                          \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/k                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/o                  size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/q                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/v                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/rms_norm/scale                   size 768          slice_size 768          Shape[d_model=768]                                          \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wi/kernel         size 2359296      slice_size 2359296      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wo/kernel         size 2359296      slice_size 2359296      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/rms_norm/scale                   size 768          slice_size 768          Shape[d_model=768]                                          \n",
            "INFO:tensorflow:Variable encoder/block_006/layer_000/SelfAttention/k                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_006/layer_000/SelfAttention/o                  size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_006/layer_000/SelfAttention/q                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_006/layer_000/SelfAttention/v                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_006/layer_000/rms_norm/scale                   size 768          slice_size 768          Shape[d_model=768]                                          \n",
            "INFO:tensorflow:Variable encoder/block_006/layer_001/DenseReluDense/wi/kernel         size 2359296      slice_size 2359296      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable encoder/block_006/layer_001/DenseReluDense/wo/kernel         size 2359296      slice_size 2359296      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_006/layer_001/rms_norm/scale                   size 768          slice_size 768          Shape[d_model=768]                                          \n",
            "INFO:tensorflow:Variable encoder/block_007/layer_000/SelfAttention/k                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_007/layer_000/SelfAttention/o                  size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_007/layer_000/SelfAttention/q                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_007/layer_000/SelfAttention/v                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_007/layer_000/rms_norm/scale                   size 768          slice_size 768          Shape[d_model=768]                                          \n",
            "INFO:tensorflow:Variable encoder/block_007/layer_001/DenseReluDense/wi/kernel         size 2359296      slice_size 2359296      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable encoder/block_007/layer_001/DenseReluDense/wo/kernel         size 2359296      slice_size 2359296      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_007/layer_001/rms_norm/scale                   size 768          slice_size 768          Shape[d_model=768]                                          \n",
            "INFO:tensorflow:Variable encoder/block_008/layer_000/SelfAttention/k                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_008/layer_000/SelfAttention/o                  size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_008/layer_000/SelfAttention/q                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_008/layer_000/SelfAttention/v                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_008/layer_000/rms_norm/scale                   size 768          slice_size 768          Shape[d_model=768]                                          \n",
            "INFO:tensorflow:Variable encoder/block_008/layer_001/DenseReluDense/wi/kernel         size 2359296      slice_size 2359296      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable encoder/block_008/layer_001/DenseReluDense/wo/kernel         size 2359296      slice_size 2359296      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_008/layer_001/rms_norm/scale                   size 768          slice_size 768          Shape[d_model=768]                                          \n",
            "INFO:tensorflow:Variable encoder/block_009/layer_000/SelfAttention/k                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_009/layer_000/SelfAttention/o                  size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_009/layer_000/SelfAttention/q                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_009/layer_000/SelfAttention/v                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_009/layer_000/rms_norm/scale                   size 768          slice_size 768          Shape[d_model=768]                                          \n",
            "INFO:tensorflow:Variable encoder/block_009/layer_001/DenseReluDense/wi/kernel         size 2359296      slice_size 2359296      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable encoder/block_009/layer_001/DenseReluDense/wo/kernel         size 2359296      slice_size 2359296      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_009/layer_001/rms_norm/scale                   size 768          slice_size 768          Shape[d_model=768]                                          \n",
            "INFO:tensorflow:Variable encoder/block_010/layer_000/SelfAttention/k                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_010/layer_000/SelfAttention/o                  size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_010/layer_000/SelfAttention/q                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_010/layer_000/SelfAttention/v                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_010/layer_000/rms_norm/scale                   size 768          slice_size 768          Shape[d_model=768]                                          \n",
            "INFO:tensorflow:Variable encoder/block_010/layer_001/DenseReluDense/wi/kernel         size 2359296      slice_size 2359296      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable encoder/block_010/layer_001/DenseReluDense/wo/kernel         size 2359296      slice_size 2359296      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_010/layer_001/rms_norm/scale                   size 768          slice_size 768          Shape[d_model=768]                                          \n",
            "INFO:tensorflow:Variable encoder/block_011/layer_000/SelfAttention/k                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_011/layer_000/SelfAttention/o                  size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_011/layer_000/SelfAttention/q                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_011/layer_000/SelfAttention/v                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_011/layer_000/rms_norm/scale                   size 768          slice_size 768          Shape[d_model=768]                                          \n",
            "INFO:tensorflow:Variable encoder/block_011/layer_001/DenseReluDense/wi/kernel         size 2359296      slice_size 2359296      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable encoder/block_011/layer_001/DenseReluDense/wo/kernel         size 2359296      slice_size 2359296      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_011/layer_001/rms_norm/scale                   size 768          slice_size 768          Shape[d_model=768]                                          \n",
            "INFO:tensorflow:Variable encoder/rms_norm/scale                                       size 768          slice_size 768          Shape[d_model=768]                                          \n",
            "INFO:tensorflow:Variable shared/embedding                                             size 24674304     slice_size 24674304     Shape[vocab=32128, d_model=768]                             \n",
            "INFO:tensorflow:Trainable Variables            count: 257     Total size: 222903552        Total slice_size: 222903552      \n",
            "INFO:tensorflow:All Variables                  count: 257     Total size: 222903552        Total slice_size: 222903552      \n",
            "INFO:tensorflow:Counters:\n",
            "allconcat: 8.32e+03\n",
            " allconcat/0: 128\n",
            "  allconcat/0/reshape_op: 128\n",
            " allconcat/1: 8.19e+03\n",
            "  allconcat/1/reshape_op: 8.19e+03\n",
            "allreduce: 5.45e+08\n",
            " allreduce/[0]: 5.45e+08\n",
            "  allreduce/[0]/einsum_op: 5.45e+08\n",
            "  allreduce/[0]/reduce_op: 64\n",
            " allreduce/[1]: 2\n",
            "  allreduce/[1]/reduce_op: 2\n",
            "einsum: 3.31e+12\n",
            "einsum_unique: 3.31e+12\n",
            "output: 2.97e+10\n",
            " output/AddOperation: 9.04e+09\n",
            " output/BinaryOpWithBroadcasting: 3.79e+07\n",
            " output/BroadcastOperation: 32\n",
            " output/Constant: 3.02e+08\n",
            " output/EinsumOperation: 7.27e+09\n",
            " output/ImportOperation: 4.21e+03\n",
            " output/MinMaxOperation: 9.44e+06\n",
            " output/OneHotOperation: 8.59e+08\n",
            " output/RangeOperation: 1.02e+03\n",
            " output/ReduceOperation: 1.13e+07\n",
            " output/ReshapeOperation: 1.97e+09\n",
            " output/ScalarAddOperation: 1.33e+07\n",
            " output/ScalarMultiplyOperation: 6.37e+07\n",
            " output/ShiftOperation: 1.64e+04\n",
            " output/SlicewiseOperation: 6.86e+09\n",
            " output/StopGradient: 2.72e+09\n",
            " output/Variable: 2.23e+08\n",
            " output/WhileLoopOperation: 3.02e+08\n",
            "output_unique: 2.97e+10\n",
            " output_unique/AddOperation: 9.04e+09\n",
            " output_unique/BinaryOpWithBroadcasting: 3.79e+07\n",
            " output_unique/BroadcastOperation: 32\n",
            " output_unique/Constant: 3.02e+08\n",
            " output_unique/EinsumOperation: 7.27e+09\n",
            " output_unique/ImportOperation: 4.21e+03\n",
            " output_unique/MinMaxOperation: 9.44e+06\n",
            " output_unique/OneHotOperation: 8.59e+08\n",
            " output_unique/RangeOperation: 1.02e+03\n",
            " output_unique/ReduceOperation: 1.13e+07\n",
            " output_unique/ReshapeOperation: 1.97e+09\n",
            " output_unique/ScalarAddOperation: 1.33e+07\n",
            " output_unique/ScalarMultiplyOperation: 6.37e+07\n",
            " output_unique/ShiftOperation: 1.64e+04\n",
            " output_unique/SlicewiseOperation: 6.86e+09\n",
            " output_unique/StopGradient: 2.72e+09\n",
            " output_unique/Variable: 2.23e+08\n",
            " output_unique/WhileLoopOperation: 3.02e+08\n",
            "variables: 2.23e+08\n",
            " variables/trainable: 2.23e+08\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from base/model.ckpt-8000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Before copy master to slices.\n",
            "INFO:tensorflow:Done with copy master to slices.\n",
            "INFO:tensorflow:decoded 0: b'function documentation generation ruby: def add ( severity , progname , & block ) return true if io . nil? || severity < level message = format_message ( severity , progname , yield ) MUTEX . synchronize { io . write ( message ) } true end'\n",
            "INFO:tensorflow:            -> b'Writes a log message if the current log level is at or below the supplied severity .'\n",
            "INFO:tensorflow:decoded 1: b'function documentation generation ruby: def add ( severity , progname , & block ) return true if io . nil? || severity < level message = format_message ( severity , progname , yield ) MUTEX . synchronize { io . write ( message ) } true end'\n",
            "INFO:tensorflow:            -> b'Writes a log message if the current log level is at or below the supplied severity .'\n",
            "INFO:tensorflow:decoded 2: b'function documentation generation ruby: def add ( severity , progname , & block ) return true if io . nil? || severity < level message = format_message ( severity , progname , yield ) MUTEX . synchronize { io . write ( message ) } true end'\n",
            "INFO:tensorflow:            -> b'Writes a log message if the current log level is at or below the supplied severity .'\n",
            "INFO:tensorflow:decoded 4: b'function documentation generation ruby: def add ( severity , progname , & block ) return true if io . nil? || severity < level message = format_message ( severity , progname , yield ) MUTEX . synchronize { io . write ( message ) } true end'\n",
            "INFO:tensorflow:            -> b'Writes a log message if the current log level is at or below the supplied severity .'\n",
            "INFO:tensorflow:prediction_loop marked as finished\n",
            "INFO:tensorflow:prediction_loop marked as finished\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "La_Lmsj1J7Wq"
      },
      "source": [
        "### Code Summarization Result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fov0lPWdD72H",
        "outputId": "d388a79b-ce12-4dd2-900c-9879e311094c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "prediction_file = \"MtfModel-output.txt-8000\"\n",
        "print(\"\\nPredictions using checkpoint 8000:\\n\" )\n",
        "with tf.io.gfile.GFile(prediction_file) as f:\n",
        "  for c, d in zip(codes, f):\n",
        "    if c:\n",
        "      print(\"Code for prediction: \" + c + '\\n')\n",
        "      print(\"Generated Documentation: \" + d)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Predictions using checkpoint 8000:\n",
            "\n",
            "Code for prediction: def add ( severity , progname , & block ) return true if io . nil? || severity < level message = format_message ( severity , progname , yield ) MUTEX . synchronize { io . write ( message ) } true end\n",
            "\n",
            "Generated Documentation: b'Writes a log message if the current log level is at or below the supplied severity .'\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}