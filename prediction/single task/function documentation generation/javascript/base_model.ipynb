{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "codeTrans_function_documentation_generation_javascript_code_base",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/agemagician/CodeTrans/blob/main/prediction/single%20task/function%20documentation%20generation/javascript/base_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9eStCoLX0pZ"
      },
      "source": [
        "**<h3>Predict the documentation for javascript code using codeTrans single task training model</h3>**\n",
        "<h4>You can make free prediction online through this \n",
        "<a href=\"https://huggingface.co/SEBIS/code_trans_t5_base_code_documentation_generation_javascript_multitask\">Link</a></h4> (When using the prediction online, you need to parse and tokenize the code first.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YPrvwDIHdBe"
      },
      "source": [
        "**1. Load necessry libraries including huggingface transformers**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FAVWAN1UOJ4"
      },
      "source": [
        "!pip install -q transformers sentencepiece"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53TAO7mmUOyI"
      },
      "source": [
        "from transformers import AutoTokenizer, AutoModelWithLMHead, SummarizationPipeline"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xq9v-guFWXHy"
      },
      "source": [
        "**2. Load the token classification pipeline and load it into the GPU if avilabile**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ybX8hZ3UcK2",
        "outputId": "47d50feb-30bd-4ed5-cb76-41d7a72bd06a"
      },
      "source": [
        "pipeline = SummarizationPipeline(\n",
        "    model=AutoModelWithLMHead.from_pretrained(\"SEBIS/code_trans_t5_base_code_documentation_generation_javascript\"),\n",
        "    tokenizer=AutoTokenizer.from_pretrained(\"SEBIS/code_trans_t5_base_code_documentation_generation_javascript\", skip_special_tokens=True),\n",
        "    device=0\n",
        ")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/models/auto/modeling_auto.py:852: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkynwKIcEvHh"
      },
      "source": [
        "**3 Give the code for summarization, parse and tokenize it**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nld-UUmII-2e"
      },
      "source": [
        "code = \"function isStandardBrowserEnv() {\\n  if (typeof navigator !== 'undefined' && (navigator.product === 'ReactNative' ||\\n                                           navigator.product === 'NativeScript' ||\\n                                           navigator.product === 'NS')) {\\n    return false;\\n  }\\n  return (\\n    typeof window !== 'undefined' &&\\n    typeof document !== 'undefined'\\n  );\\n}\" #@param {type:\"raw\"}\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJLeTZ0JtsB5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4594d2ff-dc95-4e07-839e-5f3588cb2367"
      },
      "source": [
        "!pip install tree_sitter\n",
        "!git clone https://github.com/tree-sitter/tree-sitter-javascript"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tree_sitter\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/52/26d11536a8fafaadabe9deeb0611abdd71e11602904f60a6debdde053e6f/tree_sitter-0.2.0.tar.gz (110kB)\n",
            "\r\u001b[K     |███                             | 10kB 19.4MB/s eta 0:00:01\r\u001b[K     |██████                          | 20kB 24.5MB/s eta 0:00:01\r\u001b[K     |█████████                       | 30kB 21.8MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 40kB 16.3MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 51kB 15.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 61kB 17.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 71kB 14.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 81kB 14.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 92kB 14.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 102kB 13.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 112kB 13.7MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: tree-sitter\n",
            "  Building wheel for tree-sitter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tree-sitter: filename=tree_sitter-0.2.0-cp36-cp36m-linux_x86_64.whl size=297401 sha256=f699261dbb0e31d1d44aed291a4eaf82a7f133b2332fb71cafd9ee468f592f64\n",
            "  Stored in directory: /root/.cache/pip/wheels/3b/a6/01/2290cc8441301a07e7717e9e03c6bbc0388f71c6bf1f7f37c1\n",
            "Successfully built tree-sitter\n",
            "Installing collected packages: tree-sitter\n",
            "Successfully installed tree-sitter-0.2.0\n",
            "Cloning into 'tree-sitter-javascript'...\n",
            "remote: Enumerating objects: 6, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 3106 (delta 0), reused 0 (delta 0), pack-reused 3100\u001b[K\n",
            "Receiving objects: 100% (3106/3106), 39.55 MiB | 15.71 MiB/s, done.\n",
            "Resolving deltas: 100% (2029/2029), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqACvTcjtwYK"
      },
      "source": [
        "from tree_sitter import Language, Parser\n",
        "\n",
        "Language.build_library(\n",
        "  'build/my-languages.so',\n",
        "  ['tree-sitter-javascript']\n",
        ")\n",
        "\n",
        "JAVASCRIPT_LANGUAGE = Language('build/my-languages.so', 'javascript')\n",
        "parser = Parser()\n",
        "parser.set_language(JAVASCRIPT_LANGUAGE)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLCv2Yb8t_PP"
      },
      "source": [
        "def get_string_from_code(node, lines):\n",
        "  line_start = node.start_point[0]\n",
        "  line_end = node.end_point[0]\n",
        "  char_start = node.start_point[1]\n",
        "  char_end = node.end_point[1]\n",
        "  if line_start != line_end:\n",
        "    code_list.append(' '.join([lines[line_start][char_start:]] + lines[line_start+1:line_end] + [lines[line_end][:char_end]]))\n",
        "  else:\n",
        "    code_list.append(lines[line_start][char_start:char_end])\n",
        "\n",
        "def my_traverse(node, code_list):\n",
        "  lines = code.split('\\n')\n",
        "  if node.child_count == 0:\n",
        "    get_string_from_code(node, lines)\n",
        "  elif node.type == 'string':\n",
        "    get_string_from_code(node, lines)\n",
        "  else:\n",
        "    for n in node.children:\n",
        "      my_traverse(n, code_list)\n",
        " \n",
        "  return ' '.join(code_list)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhF9MWu1uCIS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7aea41c2-8f00-41b1-8f2b-34611c8c31e3"
      },
      "source": [
        "tree = parser.parse(bytes(code, \"utf8\"))\n",
        "code_list=[]\n",
        "tokenized_code = my_traverse(tree.root_node, code_list)\n",
        "print(\"Output after tokenization: \" + tokenized_code)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Output after tokenization: function isStandardBrowserEnv ( ) { if ( typeof navigator !== 'undefined' && ( navigator . product === 'ReactNative' || navigator . product === 'NativeScript' || navigator . product === 'NS' ) ) { return false ; } return ( typeof window !== 'undefined' && typeof document !== 'undefined' ) ; }\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVBz9jHNW1PI"
      },
      "source": [
        "**4. Make Prediction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAItQ9U9UwqW",
        "outputId": "ceeb7433-aa7c-4df9-e2f5-ae126d168558"
      },
      "source": [
        "pipeline([tokenized_code])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Your max_length is set to 512, but you input_length is only 74. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'summary_text': 'Returns whether the givenEnv should be focused .'}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    }
  ]
}