{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "codeTrans_api_generation_large_multitask",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/agemagician/CodeTrans/blob/main/prediction/multitask/pre-training/api%20generation/large_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9eStCoLX0pZ"
      },
      "source": [
        "**<h3>Generate the api based on the description using codeTrans multitask training model</h3>**\n",
        "<h4>You can make free prediction online through this \n",
        "<a href=\"https://huggingface.co/SEBIS/code_trans_t5_large_api_generation_multitask\">Link</a></h4> (When using the prediction online, you need to parse and tokenize the code first.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YPrvwDIHdBe"
      },
      "source": [
        "**1. Load necessry libraries including huggingface transformers**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FAVWAN1UOJ4",
        "outputId": "ce4b297e-c769-42de-dcd7-04a59acdcbd7"
      },
      "source": [
        "!pip install -q transformers sentencepiece"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.8MB 15.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2MB 61.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.2MB 57.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 890kB 58.8MB/s \n",
            "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53TAO7mmUOyI"
      },
      "source": [
        "from transformers import AutoTokenizer, AutoModelWithLMHead, SummarizationPipeline"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xq9v-guFWXHy"
      },
      "source": [
        "**2. Load the token classification pipeline and load it into the GPU if avilabile**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ybX8hZ3UcK2",
        "outputId": "85a68cd1-3657-4307-8655-33456cbc9bb7"
      },
      "source": [
        "pipeline = SummarizationPipeline(\n",
        "    model=AutoModelWithLMHead.from_pretrained(\"SEBIS/code_trans_t5_large_api_generation_multitask\"),\n",
        "    tokenizer=AutoTokenizer.from_pretrained(\"SEBIS/code_trans_t5_large_api_generation_multitask\", skip_special_tokens=True),\n",
        "    device=0\n",
        ")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/models/auto/modeling_auto.py:970: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkynwKIcEvHh"
      },
      "source": [
        "**3 Give the description for generating api, parse and tokenize it**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nld-UUmII-2e"
      },
      "source": [
        "description = \"parse the uses licence node of this package, if any, and returns the license definition if theres\" #@param {type:\"raw\"}"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqACvTcjtwYK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed5ad23e-3db6-43bf-e096-5d76c72ba5ff"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvnBXtkJBKGJ",
        "outputId": "4c677f8f-803e-4596-a60b-383f9fd56683"
      },
      "source": [
        "\n",
        "def englishTokenizer(sentence):\n",
        "    result = []\n",
        "    tokens = word_tokenize(sentence)\n",
        "    for t in tokens:\n",
        "        if( not len(t)>50):\n",
        "            result.append(t)\n",
        "    return ' '.join(result)\n",
        "\n",
        "tokenized_description = englishTokenizer(description)\n",
        "print(\"tokenized description: \" + tokenized_description)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tokenized description: parse the uses licence node of this package , if any , and returns the license definition if theres\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVBz9jHNW1PI"
      },
      "source": [
        "**4. Make Prediction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAItQ9U9UwqW",
        "outputId": "c13d2ad5-89c4-4e0d-f3a2-9e6d5ecd823a"
      },
      "source": [
        "pipeline([tokenized_description])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'summary_text': 'one or None .'}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    }
  ]
}